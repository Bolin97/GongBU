# import gradio as gr
# import requests
# import json

# MAX_HISTORY_LEN=50

# def chat_streaming(query,history):
#     # è°ƒç”¨api_server
#     response=requests.post('http://localhost:8000/chat',json={
#         'query':query,
#         'stream': True,
#         'history':history
#     },stream=True)
    
#     # æµå¼è¯»å–http response body, æŒ‰\0åˆ†å‰²
#     for chunk in response.iter_lines(chunk_size=8192,decode_unicode=False,delimiter=b"\0"):
#         if chunk:
#             data=json.loads(chunk.decode('utf-8'))
#             text=data["text"].rstrip('\r\n') # ç¡®ä¿æœ«å°¾æ— æ¢è¡Œ
#             yield text

# with gr.Blocks(css='.qwen-logo img {height:200px; width:600px; margin:0 auto;}') as app:
#     with gr.Row():
#         logo_img=gr.Image('./qwen.png',elem_classes='qwen-logo')
#     with gr.Row():
#         chatbot=gr.Chatbot(label='é€šä¹‰åƒé—®14B-Chat-Int4')
#     with gr.Row():
#         query_box=gr.Textbox(label='æé—®',autofocus=True,lines=5)
#     with gr.Row():
#         clear_btn=gr.ClearButton([query_box,chatbot],value='æ¸…ç©ºå†å²')
#         submit_btn=gr.Button(value='æäº¤')

#     def chat(query,history):
#         for response in chat_streaming(query,history):
#             yield '',history+[(query,response)]
#         history.append((query,response))
#         while len(history)>MAX_HISTORY_LEN:
#             history.pop(0)
    
#     # æäº¤query
#     submit_btn.click(chat,[query_box,chatbot],[query_box,chatbot])
#     # query_box.submit(chat,[query_box,chatbot],[query_box,chatbot])

# if __name__ == "__main__":
#     app.queue(200)  # è¯·æ±‚é˜Ÿåˆ—
#     app.launch(server_name='0.0.0.0',max_threads=500) # çº¿ç¨‹æ± 



import gradio as gr
import httpx
import uuid
import json
from typing import List, AsyncGenerator
import pandas as pd

# é…ç½®
BACKEND_URL = "http://127.0.0.1:8002"
# ç›´æ¥è°ƒç”¨åå°æ¥å£è·å–æ”¯æŒçš„è®¿é—®çš„æ¨¡å‹
# TODO

MODELS = ["deepseek-reasoner", "Qwen-1.8B", "GPT-4", "Llama-3"]

CSS = """
.gradio-container {max-width: 1200px !important; margin: 0 auto;}
.sidebar {border-right: 1px solid #e5e7eb; height: 100vh;}
.chat-area {height: calc(100vh - 160px); overflow-y: auto;}
.input-group {position: fixed; bottom: 20px; width: 72%; background: white;}
.dark .input-group {background: #1a1a1a;}
.message-user {background: #f3f4f6; border-radius: 12px; padding: 12px;}
.message-bot {background: white; border: 1px solid #e5e7eb; border-radius: 12px; padding: 12px;}
.dark .message-bot {background: #2d2d2d;}
.model-selector {padding: 6px 16px; border-bottom: 1px solid #e5e7eb;}

.start-group {
    position: absolute;
    bottom: 500px;
    width: 83%;
}
.compact-btn {
    background: #ADD8E6;
    color: #333 !important;
    position: absolute;
    width: 100px !important;
    height: 46px;
    top: 150px;
    left: 210px;
}
.start-input{
    position: absolute;
    width: 500px;
    top: 150px;
    left: 50px;
}

#welcome-container {
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    height: 100vh;
    margin-top: -60px;
}
.action-btns {
    position: absolute;
    min-width: 90px !important; 
    width: 90px !important;
    margin-top: 110px;
    left: 50px;
}
.deep-search-btn-active {
    min-width: 90px !important; 
    background: white !important;
    color: #20B2AA !important;
    width: 90px !important;
    border-radius: 15px !important;
    font-size: 13px;  /* å­—ä½“å¤§å° */
    font-weight: bold;  /* ä¸åŠ ç²— */
    border: 2px solid rgba(51, 51, 51, 0.1); /* é»‘è‰²è¾¹æ¡†,2pxå®½ */
    height: 46px !important;
    transition: all 0.3s !important;
}
.deep-search-btn {
    min-width: 90px !important; 
    background: white !important;
    color: #333 !important;
    width: 90px !important;
    font-size: 13px;  /* å­—ä½“å¤§å° */
    font-weight: bold;  /* ä¸åŠ ç²— */
    border: 2px solid rgba(51, 51, 51, 0.1); /* é»‘è‰²è¾¹æ¡†,2pxå®½ */
    border-radius: 15px !important;
    height: 46px !important;
    transition: all 0.3s !important;
}

"""
#20B2AA æµ…ç»¿è‰²
CSS_title = """
#custom_html_section {
     display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    height: 100vh;
    margin-top: -60px;
}
"""

JS_deep_search ="""
    (btn) => {
        const deepSearchElement = document.getElementById('deep-search');
        const currentColor = window.getComputedStyle(deepSearchElement).color;
        console.log(currentColor);
        if (currentColor === 'rgb(51, 51, 51)') {  // #333 çš„ RGB å€¼
            document.getElementById('deep-search').className = 'deep-search-btn-active';  // å¦‚æœæ˜¯ #333,åˆ™æ”¹ä¸º #20B2AA
        } else if (currentColor === 'rgb(32, 178, 170)') {  // #20B2AA çš„ RGB å€¼
            document.getElementById('deep-search').className = 'deep-search-btn';  // å¦‚æœæ˜¯ #20B2AA,åˆ™æ”¹ä¸º #333
        }
    }
"""

# æ ‡é¢˜æµå¼æ‰“å°
JS_streamPrint = """
    function createGradioAnimation(){
        // æµå¼æ˜¾ç¤ºå†…å®¹é…ç½®
        const content = {
            title: "æˆ‘æ˜¯ä¹äºåŠ©äººçš„AIåŠ©æ‰‹ğŸ‰",
            subtitle: "æˆ‘å–„äºè§£å†³å„ç§é—®é¢˜ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„ï¼"
        };
        console.log(content);
        
        // æ‰“å­—æœºæ•ˆæœå®ç°
        function typeWriter(elementId, text, speed=80, callback) {
            let i = 0;
            const elem = document.getElementById(elementId);
            console
           elem.innerText = '';
            
            function type() {
                if (i < text.length) {
                    elem.innerText += text.charAt(i);
                    i++;
                    setTimeout(type, speed);
                } else if (callback) {
                    callback();
                }
            }
            type();
        }

        // å¯åŠ¨åŠ¨ç”»
        setTimeout(() => {
            typeWriter('main-title', content.title, 80, () => {
                typeWriter('subtitle', content.subtitle, 50);
            });
        }, 200); // å»¶è¿Ÿå¯åŠ¨ç¡®ä¿ç»„ä»¶åŠ è½½å®Œæˆ

    }
"""

# ä¸¥æ ¼å‰åç«¯åˆ†ç¦»çš„APIå®¢æˆ·ç«¯
class APIClient:
    @staticmethod
    async def create_session(model: str, system_prompt: str) -> dict:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{BACKEND_URL}/sessions",
                headers={"Authorization": f"Bearer {ui_state.token}"},
                json={
                    "model": model,
                    "system_prompt": system_prompt,
                }
            )
            return response.json()

    @staticmethod
    async def get_infer_point() -> List:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{BACKEND_URL}/infer/model/infer_points",
                                        headers={"Authorization": f"Bearer {ui_state.token}"})
            MODELS =  await response.json()

BASE_URL = "http://127.0.0.1:8002/ai"  # æ›¿æ¢ä¸ºä½ çš„å®é™…æœåŠ¡å™¨åœ°å€

# æ¨¡æ‹Ÿè·å–JWT Token
def get_jwt_token():
    # åœ¨è¿™é‡Œå®ç°è·å–JWT tokençš„é€»è¾‘ï¼Œå‡è®¾å®ƒæ˜¯é™æ€çš„
    return "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJhdXJvcmF5dWh1IiwiZXhwIjoxNzUzNDE5NTY0fQ.piS8S7NbHT1HQixP8tzzD8TYcu6Yh0FZeJjTlhWFCtM"


# GET /sessions æ¥å£
async def get_sessions():
    url = f"{BASE_URL}/sessions"
    headers = {"Content-Type": "application/json",
               "Authorization": f"Bearer {get_jwt_token()}"
               }
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.get(url,headers=headers)
        return response.json()

# GET /session/{session_id} æ¥å£
async def get_session_messages(session_id: str):
    url = f"{BASE_URL}/session/{session_id}"
    
    async with httpx.AsyncClient() as client:
        response = await client.get(url)
        return response.json()

# æµå¼èŠå¤©æ¥å£
async def chat_stream(session_id: str, model: str, message: str, is_stream: bool, deep_think: bool):
    url = f"{BASE_URL}/chat"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {get_jwt_token()}"
    }
    payload = {
        "model": model,
        "sessionId": session_id,
        "message": message,
        "stream": is_stream,
        "deep_think": deep_think
    }

    async with httpx.AsyncClient(timeout=90.0) as client:
        if is_stream:
            async with client.stream("POST", url, headers=headers, json=payload) as response:
                reasoning_count = 0
                content_count = 0
                full_resp = ''
                async for chunk in response.aiter_bytes():
                    data = json.loads(chunk)

                    if data.get("reasoning_content"):
                        if reasoning_count == 0:
                            full_resp += '[å¼€å§‹æ€è€ƒ]\n'
                        full_resp += data["reasoning_content"]
                        reasoning_count += 1

                    if data.get("content"):
                        if reasoning_count == 0:
                            replace_resp = data["content"].replace('<think>', '[å¼€å§‹æ€è€ƒ]\n').replace('</think>', '\n[ç»“æŸæ€è€ƒ]\n')
                            full_resp += replace_resp
                        else:
                            if content_count == 0:
                                full_resp += '\n[ç»“æŸæ€è€ƒ]\n'
                            full_resp += data["content"]
                            content_count += 1

                    yield full_resp
        else:
            # éæµå¼ï¼šä¸€æ¬¡æ€§å“åº”ï¼Œç›´æ¥è·å– JSON æ•°æ®
            response = await client.post(url, headers=headers, json=payload)
            if response.status_code == 200:
                data = response.json()
                yield data["reply"]
            else:
                print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å†…å®¹: {response.text}")


# POST /create_session æ¥å£
async def create_session(model:str, message:str):
    url = f"{BASE_URL}/create_session"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {get_jwt_token()}"
    }
    payload = {
        "model": model,
        "message":  message
    }

    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.post(url, headers=headers, json=payload)
        print(f"Create session response: {response.json()}")
        return response.json()

# å‰ç«¯çŠ¶æ€ç®¡ç†
class UIState:
    def __init__(self):
        
        self.current_session = None
        self.selected_model = MODELS[0]
        self.session_list = []
        # ç”¨æˆ·æ˜¯å¦é€‰æ‹©äº†æ·±åº¦æœç´¢
        self.deep_think = True
        self.token = None
        # <think>

ui_state = UIState()


# åˆ›å»ºæ–°ä¼šè¯
async def create_new_session(model: str, start_input: str):
    response = await create_session(model, start_input)
    ui_state.current_session = response["id"]
    ui_state.selected_model = model
    # è·å–ä¼šè¯æ•°æ®å­˜å‚¨åœ¨å‰ç«¯UIä¸­ 
    session_list = await refresh_session_list()
    yield [   
            '',
            gr.update(visible=False),  # éšè—æ¬¢è¿é¡µ
            gr.update(visible=True),   # æ˜¾ç¤ºèŠå¤©é¡µ
            session_list,
            gr.update( visible=False),  # éšè—æ¨¡å‹é€‰æ‹©æ¡†
            gr.update(value=ui_state.selected_model, visible=True), #æ˜¾ç¤ºé€‰æ‹©æ¨¡å‹
            [(start_input,'')]
        ] 
    # å¼‚æ­¥è°ƒç”¨
    async for chat_history in handle_stream_response(current_session, model, start_input, ui_state.deep_think):
        yield [
            '',   
            gr.update(visible=False),  # éšè—æ¬¢è¿é¡µ
            gr.update(visible=True),   # æ˜¾ç¤ºèŠå¤©é¡µ
            session_list,
            gr.update( visible=False),  # éšè—æ¨¡å‹é€‰æ‹©æ¡†
            gr.update(value=ui_state.selected_model, visible=True), #æ˜¾ç¤ºé€‰æ‹©æ¨¡å‹
            [(start_input, chat_history)]
            
        ]
# åˆ·æ–°ä¼šè¯åˆ—è¡¨
async def refresh_session_list():
    
    sessions = await get_sessions()
    # æŒ‰ç…§ä¿®æ”¹æ—¶é—´æ’åº
    sessions.sort(key=lambda x: x['updated_at'], reverse=True)
    ui_state.session_list = sessions
    return [[s["title"]] for s in ui_state.session_list]

# å¤„ç†æ¶ˆæ¯æµå¼å“åº”
async def handle_stream_response(session_id: str, model:str, message: str, deep_think, is_stream:bool = True):
    async for chunk in chat_stream(session_id, model, message, is_stream, deep_think):
        yield chunk

# ä¸»æ¶ˆæ¯å¤„ç†æµç¨‹
async def process_message(history:list, message: str):
    yield [   
            history  + [(message,'')]
        ] 
    # å¼‚æ­¥è°ƒç”¨
    async for chat_history in handle_stream_response(ui_state.current_session, ui_state.selected_model, message, ui_state.deep_think):
        yield [
            history + [(message, chat_history)]
        ]

# ä¼šè¯ç‚¹å‡»å¤„ç†
async def load_session(evt: gr.SelectData, history: list):
    # æ ¹æ®é€‰æ‹©çš„index, è·å–é€‰æ‹©çš„ä¼šè¯æ•°æ®
    selected_session = ui_state.session_list[evt.index]
    if selected_session["title"] != evt.value:
        return [
            history,
            gr.update(value=ui_state.selected_model)
        ]
    ui_state.current_session = selected_session['id']
    ui_state.selected_model = selected_session["model"]
    session_history = await get_session_messages(selected_session['id'])
    # å°†è¿”å›è½¬åŒ–ä¸ºchatboxéœ€è¦çš„å…ƒç»„
    chat_history = []
    current_user_msg = None
    for msg in session_history:
        role = msg.get("role")
        content = msg.get("content", "")

        if role == "user":
            # å¦‚æœä¹‹å‰å·²ç»æœ‰æœªåŒ¹é…çš„ userï¼Œå…ˆå°†å…¶é…å¯¹ä¸ºç©ºå›ç­”
            if current_user_msg is not None:
                chat_history.append((current_user_msg, ""))
            current_user_msg = content

        elif role == "assistant":
            if current_user_msg is not None:
                chat_history.append((current_user_msg, content))
                current_user_msg = None
            else:
                # æ²¡æœ‰ user å´æ¥ assistantï¼Œé»˜è®¤å¿½ç•¥ï¼ˆå¯æŒ‰éœ€å¤„ç†ï¼‰
                pass

    # å¦‚æœæœ€åè¿˜æœ‰æœªåŒ¹é…çš„ userï¼Œè¡¥ç©ºåŠ©æ‰‹å›ç­”
    if current_user_msg is not None:
        chat_history.append((current_user_msg, ""))

    return [
        chat_history,
        gr.update(value=selected_session["model"])
    ]

async def switch_deep_search():
   ui_state.deep_think = not ui_state.deep_think


# æ–°å»ºä¼šè¯è¿”å›ä¸»é¡µé¢
async def create_new_chat():
    # æ¸…ç©ºUIçŠ¶æ€
    ui_state.current_session = None
    ui_state.selected_model = None
    return [   
            gr.update(visible=True),  # è¿”å›æ¬¢è¿é¡µ
            gr.update(visible=False),   # éšè—èŠå¤©é¡µ
            gr.update(visible=True),  # å›åˆ°æ¨¡å‹é€‰æ‹©æ¡†
            gr.update(visible=False), # éšè—é€‰æ‹©æ¨¡å‹
            gr.update(choices=MODELS,value=MODELS[0]),
        ]



async def save_token_to_state(token):
    """è¿™ä¸ªå‡½æ•°åœ¨é¡µé¢åŠ è½½æ—¶è°ƒç”¨,æŠŠæå–åˆ°çš„tokenä¿å­˜åˆ°UIState"""
    ui_state.token = token
    print(f"[Info] ä¿å­˜äº†Token: {token}")
    return [await refresh_session_list()]

# è¿™ä¸ªJSè„šæœ¬ï¼Œæå–URLé‡Œçš„ `id=xxx`
GET_TOKEN_FROM_URL = """
() => {
    const params = new URLSearchParams(window.location.search);
    const token = params.get('id'); 
    console.log("æå–åˆ°Token: ", token);
    return token || "";
}
"""

CSS += """
/* é’è‰²è°ƒæŒ‰é’® */
.cyan-btn {
    background: #00bcd4 !important;
    color: white !important;
    border: none !important;
}

/* å†å²ä¼šè¯æ ‡é¢˜æ ·å¼ */
.history-header {
    margin: 15px 0 !important;
    color: #333 !important;
}

/* ç´§å‡‘å‹è¡¨æ ¼æ ·å¼ */
.compact-table table {
    border-collapse: collapse !important;
    width: 100% !important;
}

.compact-table th {
    display: none !important; /* éšè—è¡¨å¤´ */
}

.compact-table td {
    padding: 12px 8px !important;
    border-bottom: 1px solid #eee !important;
    font-size: 14px !important;
    line-height: 1.4 !important;
}

.compact-table tr:last-child td {
    border-bottom: none !important;
}

.compact-table tr:hover td {
    background: #f8f8f8 !important;
    cursor: pointer;
}
"""

# æ ‡é¢˜æµå¼æ‰“å°
with gr.Blocks(css=CSS, title="AI Assistant", js=JS_streamPrint) as app:
    # å…¨å±€çŠ¶æ€
    current_session = gr.State()
    
    with gr.Row():
        # å·¦ä¾§ä¼šè¯åˆ—ï¼ˆä¼˜åŒ–åï¼‰
        with gr.Column(scale=1, elem_classes="sidebar"):
            create_btn = gr.Button("æ–°å»ºä¼šè¯", variant="primary", elem_classes="cyan-btn")
            gr.Markdown("### å†å²ä¼šè¯", elem_classes="history-header")
            
            # ä¼˜åŒ–åçš„å†å²ä¼šè¯åˆ—è¡¨
            session_list = gr.Dataframe(
                headers=["ä¼šè¯æ ‡é¢˜", "æ—¥æœŸ"],
                interactive=False,
                datatype=["str", "str"],
                height="85vh",
                elem_classes="compact-table",
                value=[
                    ["å¦‚ä½•é…ç½®ç½‘ç»œï¼Ÿ", "2025/04/29"],
                    ["ç³»ç»Ÿå®‰è£…é—®é¢˜", "2025/04/29"]
                ]
            )

        # å³ä¾§ä¸»å†…å®¹
        with gr.Column(scale=3):
            # æ¨¡å‹é€‰æ‹©å™¨
            with gr.Row(visible=True) as model_selector:
                model_dropdown = gr.Dropdown(
                    MODELS,
                    value=MODELS[0],
                    label="é€‰æ‹©æ¨¡å‹",
                    show_label=False,
                    # container=False,
                    elem_classes="model-selector"
                )
            with gr.Row(visible=False) as model_selected:
                gr.Markdown(f"### {ui_state.selected_model}", elem_classes="model-selector")

            
            # èŠå¤©åŒºåŸŸ
            with gr.Column(visible=False) as chat_container:
                chatbot = gr.Chatbot(
                    elem_classes="chat-area",
                    bubble_full_width=False,
                    show_label=False
                )
                
                with gr.Row(elem_classes="input-group"):
                    with gr.Column(scale=6):
                        msg_input = gr.Textbox(
                            label="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ",
                            show_label=False,
                            placeholder="åœ¨æ­¤è¾“å…¥æ‚¨çš„é—®é¢˜..."
                            # container=False,
                            # lines=2
                        )
                    with gr.Column(scale=1):
                        send_btn = gr.Button("å‘é€", variant="primary")

            # æ¬¢è¿é¡µé¢
            with gr.Column(visible=True,elem_id='welcome-container') as welcome:
                # gr.Markdown("æˆ‘æ˜¯ä¹äºåŠ©äººçš„AIåŠ©æ‰‹ğŸ‰", elem_id="welcome-title")
                # gr.Markdown("æˆ‘å¯ä»¥å¸®åŠ©æ‚¨è§£å†³å„ç§é—®é¢˜ï¼Œè¯·å¼€å§‹å¯¹è¯å§ï¼", elem_id="welcome-description")
            
                # ä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œè¿™é‡Œä½¿ç”¨jsçš„æ—¶å€™ä¸ç”Ÿæ•ˆï¼Œåªæœ‰æœ€å¤–é¢åœ¨è¿™å±‚blockä½¿ç”¨jsæ‰ç”Ÿæ•ˆ
                # with gr.Blocks(css=CSS_title,js=JS_streamPrint) as app1:
                with gr.Blocks(css=CSS_title) as app1:
                    with gr.Column(elem_id="custom_html_section"):
                        gr.HTML("""
                            <div class="welcome-container">
                                <h1 id="main-title" class="welcome-title" style="font-size: 2rem !important; font-weight: 700 !important;  margin-top: 340px  !important;
                                    text-align: center;">
                                    </h1>
                                <div style=" color: #666;margin-bottom: 440px;text-align: center;">
                                    <span id="subtitle" ></span>
                                </div>
                            </div>
                                
                        """)
                with gr.Row(elem_classes="start-group"):
                    with gr.Column(scale=8):
                        start_input = gr.Textbox(
                            label="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ",
                            show_label=False,
                            container=False,
                            placeholder="åœ¨æ­¤è¾“å…¥æ‚¨çš„é—®é¢˜...",
                            elem_classes="start-input"
                        )
                    with gr.Column(scale=1):
                        start_btn = gr.Button(
                            'å‘é€',
                            icon='../icon/send.png',
                            variant="primary",
                            elem_classes="compact-btn"
                        )
                    with gr.Row(visible=True, elem_classes="action-btns"):
                            deep_search_btn = gr.Button(
                                "æ·±åº¦æœç´¢",
                                elem_classes="deep-search-btn-active",
                                elem_id = "deep-search"
                            )

    # æœ‰äº›æ¨¡å‹ä¸æ”¯æŒæ·±åº¦æœç´¢
    model_dropdown.change(
        lambda x: setattr(ui_state, "selected_model", x),
        model_dropdown
    )
    # å°†å¤šä¸ªè§¦å‘å™¨ç»‘å®šåˆ°åŒä¸€å‡½æ•° ----> æ”¯æŒç‚¹å‡»æäº¤æŒ‰é’®ï¼Œæˆ–è€…æŒ‰ä¸‹å›è½¦é”®æ¥æäº¤
    gr.on(
        triggers=[start_input.submit, start_btn.click],
        fn=create_new_session,
        inputs=[model_dropdown, start_input],
        outputs=[start_input, welcome, chat_container, session_list, model_selector,model_selected, chatbot])


    send_btn.click(
        process_message,
        [chatbot, msg_input],
        [chatbot]
    )

    session_list.select(
        load_session,
        [chatbot],
        outputs=[chatbot, model_dropdown]
    )

    create_btn.click(
        create_new_chat,
        [],
        [welcome, chat_container, model_selector,model_selected, model_dropdown]
    )
    # æ·±åº¦æœç´¢æŒ‰é’®äº¤äº’
    deep_search_btn.click(
        switch_deep_search,
        js=JS_deep_search
    )

    # é¡µé¢ä¸€åŠ è½½ï¼Œè°ƒç”¨JSæå–token
    app.load(save_token_to_state, inputs=[], outputs=[session_list], js=GET_TOKEN_FROM_URL)

if __name__ == "__main__":
    app.queue(500)  # è¯·æ±‚é˜Ÿåˆ—
    app.launch(server_name='0.0.0.0', share=True, max_threads=200) # çº¿ç¨‹æ± 

# çƒ­æ›´æ–°å¯åŠ¨
# gradio gradio_webui.py --demo-name=app
